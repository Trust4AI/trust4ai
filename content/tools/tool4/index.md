---
title:  GUARD-ME. AI-guided Evaluator for Bias Detection using Metamorphic Testing
summary: #GUARD-ME evaluates bias in AI-enabled search engines by evaluating the responses to the source and follow-up test cases. It utilizes Large Language Models (LLMs) to detect any bias and ensure that these systems adhere to ethical standards. This tool is complementary to MUSE, which generates the test cases used, and GENIE, which facilitates communication with LLMs.<br>
  To use GUAR-ME follow the instructions in the github link below. 
#[GitHub](https://github.com/Trust4AI/GUARD-ME) # SHORT DESCRIPTION

image: 
  placement: 1
  focal_point: 'TopLeft'
  preview_only: false
  alt_text: Logo.

links:
  - icon: github 
    icon_pack: fab
    name: GitHub
    url: https://github.com/Trust4AI/GUARD-ME

date: 2024-09-17

publication_types: 
- "paper-conference"

---

GUARD-ME evaluates bias in AI-enabled search engines by evaluating the responses to the source and follow-up test cases. It utilizes Large Language Models (LLMs) to detect any bias and ensure that these systems adhere to ethical standards. This tool is complementary to MUSE, which generates the test cases used, and GENIE, which facilitates communication with LLMs.

Integration options include a Docker image that launches a REST API with interactive documentation, simplifying its use and integration into various systems. GUARD-ME is part of the Trust4AI research project.
